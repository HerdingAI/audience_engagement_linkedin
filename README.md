# LinkedIn-Engagement

A Python-based automation suite for LinkedIn engagement, including post retrieval, liking, commenting, and AI-powered comment generation. Designed to help businesses and professionals streamline outreach, interaction, and data collection on LinkedIn.

## Features

- Build and maintain LinkedIn graph stored in SQLite
- Retrieve posts from first-degree connections and target prospects
- Automatically like posts from the fetched dataset
- AI-generated comments using OpenAI and Google Generative AI
- Post generated comments on LinkedIn
- Structured logging and CSV export for audit and analysis
- Configurable scheduling within scripts via Python `schedule`

## Directory Structure

```
/ (root)
├─ backend/                           # Core services and graph logic
│  ├─ invitations/                   # Invitation graph and SQLite service
│  └─ linkedin/                      # LinkedIn graph, nodes, and storage service
├─ multimedia/                       # Downloaded media assets
├─ *.py                              # Main scripts (retrieval, liking, commenting, generation)
├─ requirements.txt                  # Python dependencies
├─ .env                              # Environment variables file (ignored by Git)
├─ README.md                         # Project overview (this file)
```

## Application Workflow

A typical execution flow of the LinkedIn-Engagement suite:

1. Build and Update LinkedIn Graph
   - Backend services in `backend/invitations` and `backend/linkedin` populate and maintain the SQLite database (`linkedin_project_db.sqlite3`).

2. Retrieve Posts
   - Use `retrieve_post_1stconnections.py` (first-degree connections) or `retrieve_posts_prospects.py` (custom prospect lists) to fetch posts and store them as CSV or in the database.

3. Like Posts
   - Run `linkedin_post_liker.py` to like posts from the fetched dataset.

4. Generate Comments
   - Run `comment_generator.py` which leverages OpenAI or Google Generative AI to create personalized comments.

5. Post Comments
   - Run `linkedin_commenter.py` to post the generated comments on LinkedIn.

6. (Optional) Send Invitations
   - Use custom endpoint scripts or the `Code_W_Other_API_Endpoints` directory to send connection invitations.

7. Logging and Reporting
   - All scripts log actions to `*.log` files and export CSV reports for audit and analysis.

8. Scheduling
   - Automate workflows with `setup_automation.sh` or configure cron jobs via `crontab_setup.txt`.

## Database Files

To understand the database state generated by the application, you'll often see the following SQLite files in the project root:

- `linkedin_project_db.sqlite3`: The primary SQLite database file storing graph data and retrieved posts.
- `linkedin_project_db.sqlite3-shm`: The shared-memory file used by SQLite when operating in WAL (Write-Ahead Logging) mode.
- `linkedin_project_db.sqlite3-wal`: The write-ahead log file that stores recent changes before they are committed to the main database. It ensures atomic transactions and crash recovery.

## Getting Started

### Prerequisites

- Python 3.10+ installed
- A valid LinkedIn account
- OpenAI and/or Google Generative AI API key(s)

### Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/Data-Carlos/LinkedIn-engagement.git
   cd LinkedIn-engagement
   ```
2. Create and activate a virtual environment:
   ```bash
   python3 -m venv venv
   source venv/bin/activate
   ```
3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

### Configuration

1. Copy `.env.example` to `.env` (or create a new `.env` file in root):
   ```bash
   cp .env.example .env
   ```
2. Populate the following environment variables in `.env`:
   ```ini
   LINKEDIN_USERNAME=<your_linkedin_email>
   LINKEDIN_PASSWORD=<your_linkedin_password>
   OPENAI_API_KEY=<your_openai_key>
   GOOGLE_API_KEY=<your_google_ai_key>       # optional
   DB_PATH=./linkedin_project_db.sqlite3
   ```

### Usage

#### Retrieve Posts

- From first-degree connections:
  ```bash
  python retrieve_post_1stconnections.py
  ```
- From target prospects list:
  ```bash
  python retrieve_posts_prospects.py --input prospects.csv
  ```

#### Engagement Actions

- Like posts:
  ```bash
  python linkedin_post_liker.py --source posts.csv
  ```
- Generate comments using AI:
  ```bash
  python comment_generator.py --source posts.csv --output comments.csv
  ```
- Post comments:
  ```bash
  python linkedin_commenter.py --source comments.csv
  ```
- Combined posting and generation sequence:
  ```bash
  sh setup_automation.sh
  ```

### Scheduling

- Use Python scheduler within scripts to run at intervals.
- Or configure a cron job described in `crontab_setup.txt`:
  ```bash
  crontab crontab_setup.txt
  ```

## Logs and Reports

All scripts write detailed logs to `*.log` files in root. CSV exports of comments, prospects, and engagement metrics are saved alongside logs for review.

## Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/xyz`)
3. Commit your changes (`git commit -m "Add xyz feature"`)
4. Push to your branch (`git push origin feature/xyz`)
5. Open a Pull Request

## License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.